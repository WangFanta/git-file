须知：只有TCP有粘包现象，UDP永远不会粘包
发送数据时间间隔很短，数据了很小，会合到一起，产生粘包
range返回一个列表，xrange是生成一个生成器对象，python已经取消xrange
yml - 是列表
.format在许多方面看起来更便利.对于%最烦人的是它无法同时传递一个变量和元组.

线程占有的都是不共享的，其中包括：栈、寄存器、状态、程序计数器
线程间共享的有：堆，全局变量，静态变量；
进程占有的资源有：地址空间，全局变量，打开的文件，子进程，信号量、账户信息

python manage.py makemigrations appname
python manage.py migrate appname

python manage.py runserver 0.0.0.0:8000

onblur="return check()"
<input type="button" value="提交" onclick="check()"/>

MVC是众所周知的模式，即：将应用程序分解成三个组成部分:model(模型),view(视图),和 controller(控制 器)。其中：
             M 管理应用程序的状态（通常存储到数据库中），并约束改变状态的行为（或者叫做“业务规则”）。
             C 接受外部用户的操作，根据操作访问模型获取数据，并调用“视图”显示这些数据。控制器是将“模型”和“视图”隔离，并成为二者之间的联系纽带。
             V 负责把数据格式化后呈现给用户。

中间件：介于操作系统和应用程序之间的产品，中间件简单解释，你可以理解为面向信息系统交互，集成过程中的通用部分的集合，屏蔽了底层的通讯，
交互，连接等复杂又通用化的功能，以产品的形式提供出来，系统在交互时，直接采用中间件进行连接和交互即可，避免了大量的代码开发和人工成本。

map(square, [1,2,3,4,5])   [1, 4, 9, 16, 25]
map(lambda x: x ** 2, [1, 2, 3, 4, 5])   [1, 4, 9, 16, 25]
map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10])   [3, 7, 11, 15, 19]

a.sort()     是在原列表上进行排序，没有返回值！！！而且只能是对列表排序！
b=sorted(a)  sorted生成一个新的列表！不管是什么，都生成一个列表，有返回值，可以对所有可迭代对象！
a.reverse()  是在原列表上进行修改，没有返回值！！！也是只能对列表排序！
b=list(reversed(a))  reversed生成新的列表，必须前面加上list(),加str()没有用！！！也就是说生成一个可迭代对象，可用for

字符串转为列表可以用list(str),也可以用str.split()  字符串  str.find("a")   str.index("a")(会报异常) 
列表转为字符串用" ".join(list)                           str.count("a")   "+".join(str)会以每个字母分开
                                                        str.strip('*'),左右删除* 生成一个新的，不是在源字符串修改
                                                        str.replace("is", "was", 3) is替换为was,替换3次数,生成新的,不是在源字符串修改

列表  
list.extend()无返回值,一次性增加一个列表  list.append("a") 添加一个
list.remove()无返回值,原列表修改

字典
dict = {'Name':'Runoob','Age':7}
dict2 = {'Sex':'female'} 
dict.update(dict2)        更新字典

fromkeys
seq = ('Google', 'Runoob', 'Taobao')
dict = dict.fromkeys(seq)
print "新字典为 : %s" %  str(dict)
dict = dict.fromkeys(seq, 10)
print "新字典为 : %s" %  str(dict)

dict.get('Sex', "NA")  可取值也可以赋值
dict.items()遍历所有键值对 生成一个遍历对象
a.values()和a.keys()会生成一个遍历对象，for来便利,如果不用for,要用list
dict.pop("key")

集合
a.add()和a.update()
a.remove()

垃圾回收机制   还有一个__del__方法，会在计数为0的时候进行调用
Python中的垃圾回收是以引用计数为主，分代收集为辅。引用计数的缺陷是循环引用的问题。
在Python中，如果一个对象的引用数为0，Python虚拟机就会回收这个对象的内存。
对象的别名被赋予新的对象会-1
循环引用，会导致无法回收他们，造成内存泄漏
引入gc模块，gc.collect()会回收，0代表只检查第一代的对象，
1代表检查一，二代的对象，2代表检查一，二，三代的对象，如果不传参数，执行一个full collection，也就是等于传2。
触发垃圾回收：调用gc.collect()/当达到阈值的时候也会被回收，阈值可以通过gc.get_count()来查看/程序退出的时候

产生死锁的条件：
资源独占排他使用/不可剥夺的条件（在未使用完毕之前不会被剥夺）/在申请新资源的时候同时占用原来的资源/等待（p2等p1的资源，p3等p2的资源）

read是读取整个文件，readline如果加上数字就变成了读取多少个字节，readlines是会生成一个迭代器需要用for循环来做

select 连接数量受限，查找速度慢，数据由内核拷贝到用户态   poll改善了第一个，epoll改善了三个
其中epoll LT可以理解为水平触发，只要有数据可以读，不管怎样都会通知。而ET为边缘触发，只有状态发生变化时才会通知，可以理解为电平变

调度算法
先来先服务/短作业优先/最高优先权调度/
时间片轮转（sched模块，
def perform_command(cmd, inc):         
#    os.system(cmd)  
    print(time.time())  
    print('zhixing写入数据库',time.time() -tt)    
    global tt  
    tt=time.time()           
def timming_exe(cmd, inc = 60):         
    # enter用来安排某事件的发生时间，从现在起第n秒开始启动        
    schedule.enter(inc, 0, perform_command, (cmd, inc))          一个enter再用一个run方法      
    #  # 持续运行，直到计划时间队列变成空为止         
    schedule.run()  ）

new方法 会执行
class Dog(object):
    __instance = None
    __init_flag = False

    def __new__(cls, name):
        if cls.__instance == None:
            cls.__instance = object.__new__(cls)
            return cls.__instance
        else:
            #返回上一次创建的对象的引用
            return cls.__instance

深浅拷贝和赋值
a=2
b=a
print id(a),id(b) #46751984 46751984
a=3
print b,id(a) #2 46751960

a=2
b=2    #这时候id也是一样的

c=[1]
d=c
print id(d),id(c) #49133256 49133256     
c.append(2)
print d#[1, 2]         字符串str、元组tuple都是不可变类型。而列表list、字典dict是可变类型

import copy
e=[3,4,["aaa","bbb"]]
f=copy.copy(e)
g=copy.deepcopy(e)
print id(e),id(f) # 49134152 49150984
e.append(5)
e[2].append("ccc")
print f#[3, 4, ['aaa', 'bbb', 'ccc']]
print g#[3, 4, ['aaa', 'bbb']]

sbuprocess模块
import subprocess
a=subprocess.check_output("ls")
b=subprocess.call("ifconfig")   #正确执行返回0，没有正确执行就报错
print a
print b

在外面输入参数
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('integer', type=int, help='display an integer')
args = parser.parse_args()
print(args.integer)

parser = argparse.ArgumentParser()
parser.add_argument("--square", help="display a square of a given number", type=int)
parser.add_argument("--cubic", help="display a cubic of a given number", type=int)
args = parser.parse_args()

if args.square:
    print(args.square ** 2)
if args.cubic:     #可以既输入square又输入cubic
    print(args.cubic ** 3)


json是可以在不同语言之间交换数据的，而pickle只在python之间使用。
json只能序列化最基本的数据类型，而pickle可以序列化所有的数据类型，包括类，函数都可以序列化。

去重
l1 = ['b','c','d','b','c','a','a']
l2 = {}.fromkeys(l1).keys()
print l2

HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，
服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。
HTTP 1.1支持持久连接，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。
HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端
请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。

#logger
import logging
#默认是warning  还有debug,这个是最低的
logging.basicConfig(level=logging.DEBUG,#调整从哪个级别开始出来
                    format="%(asctime)s%(filename)s[line:%(lineno)d] %(levelname)s \
                    %(message)s",#lineno行号。格式都是自己定的
                    datefmt="%a,%d %b %Y %H:%M:%S",#依次向上对应
                    filename="./testhappy.log",
                    filemode="a")
logging.debug(msg='debug message')
logging.info(msg='info message')
logging.warning(msg='warning message')
logging.error(msg='error message')
logging.critical(msg='critical message')
#
#
logger=logging.getLogger("传进的字符串作为日志名字")

#logger=logging.getLogger("bmc bug")
logger.setLevel(logging.DEBUG)#设定日志的级别
#也可以通过下面的这种方式来设定级别
    #logger=logging.Logger("bmc bug",level=logging.INFO)
fh=logging.FileHandler("qwer.log")#文件显示
ch=logging.StreamHandler()#屏幕显示
formatter=logging.Formatter("%(asctime)s-%(name)s-%(levelname)s-%(message)s")
fh.setFormatter(formatter)#把格式装进去
ch.setFormatter(formatter)

logger.addHandler(fh)#把各种显示加进去
logger.addHandler(ch)

logger.info("info message")
logger.warning("warning message")
logger.error("error message")
logger.critical("critical message")
#可以写成函数的形式，然后return logger，然后在调用的地方写sss.info("asdf")

select
import socket,time，select
sk=socket.socket()
sk.bind(('127.0.0.1',8080))
sk.listen(3)
sk1=socket.socket()
sk1.bind(('127.0.0.1',8080))
sk1.listen(3)
# select中第1个参数表示inputs中发生变化的句柄放入r_list。
# select中第2个参数表示[]中的值原封不动的传递给w_list。
# select中第3个参数表示inputs中发生错误的句柄放入e_list。
while True:
    r, w, e = select.select([sk,sk1], [], [], 5)  # 监听多少秒 
    for i in r:#r是个列表
        conn,addr = i.accept()
        print('hello')
    print(r)#只要上面的数据没有使用，r就会一直有
    
多进程
1       用os.fork() 旨在linux里面可以用，Windows不可用
2       用multiprocessor模块
import os, time
from multiprocessing import Process
def worker():
    print("子进程执行中>>> pid={0},ppid={1}".format(os.getpid(), os.getppid()))
    time.sleep(2)
    print("子进程终止>>> pid={0}".format(os.getpid()))
def main():
    print("主进程执行中>>> pid={0}".format(os.getpid()))
    ps = []
    # 创建子进程实例
    for i in range(2):
        p = Process(target=worker, name="worker" + str(i), args=())
        ps.append(p)
    # 开启进程
    for i in range(2):
        ps[i].start()
    # 阻塞进程
    for i in range(2):
        ps[i].join()
    print("主进程终止")
    
3       用multiprocessor里面的poll方法
from multiprocessing import Pool
import time
def f(x):
  for i in range(10):
    print (i,'-----------',x)
    time.sleep(1)
def main():
  #控制进程池的大小为4个进程（可以自行改动测试）
  pool = Pool(processes=4)
  for x in range(10):
    #添加进程入进程池，注意加"_async",apply为阻塞版本,参数分别为target和args
    result = pool.apply_async(f,(x*10,))
  pool.close()
  pool.join()
  if result.successful():
    print( 'successful')
if __name__ == "__main__":
  main()

异步io
用asyncio
import threading
import asyncio

@asyncio.coroutine
def hello():
    print('Hello world! (%s)' % threading.currentThread())
    yield from asyncio.sleep(1)
    print('Hello again! (%s)' % threading.currentThread())
loop = asyncio.get_event_loop()
tasks = [hello(), hello()]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()
